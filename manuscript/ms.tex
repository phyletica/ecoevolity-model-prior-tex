%&<latex>
\documentclass[letterpaper,12pt]{article}
\pdfoutput=1

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% preamble %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../utils/preamble.tex}
\input{../utils/environments.tex}
\input{../utils/macros.tex}
\input{../utils/notation.tex}

\newcommand{\ifdoublespacing}[2]{#1}
% \newcommand{\ifdoublespacing}[2]{#2}
\newcommand{\iflinenumbers}[2]{#1}
% \newcommand{\iflinenumbers}[2]{#2}
% \newcommand{\ifragged}[2]{#1}
\newcommand{\ifragged}[2]{#2}

\usepackage[round]{natbib}
\usepackage{amsmath}
\title{A Pitman-Yor process prior for estimating shared evolutionary events}
% \title{Comparing hiearchicial Bayesian priors for estimating shared evolutionary events}

\author[1]{Tashitso Anamza}
\author[1]{Tanner Myers}
\author[1]{Randy Klabacka}
\author[1]{Perry L.\ Wood, Jr.}
\author[1]{Claire Tracy}
\author[1]{Kerry Cobb}
\author[1]{Matthew Buehler}
\author[1]{Jamie R.\ Oaks \thanks{Corresponding author: \href{mailto:joaks@auburn.edu}{\tt joaks@auburn.edu}}}
\affil[1]{Department of Biological Sciences \& Museum of Natural History, Auburn University, Auburn, Alabama 36849}

\date{\today}

\makeatletter
\let\msTitle\@title
\let\msAuthor\@author
\let\msDate\@date
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\ifragged{
\raggedright
}{}

\iflinenumbers{
\begin{linenumbers}
}{}

\textbf{Running head}: \uppercase{Estimating shared evolutionary events}

{\let\newpage\relax\maketitle}

\newpage

\ifdoublespacing{
\doublespacing
}{}

\begin{abstract}
Evolutionary biologists are interested in investigating the evolutionary history of the species. phylogenetic models are one of the means that allow them to model the world or the evolutionary processes that are responsible for generating biodiversity patterns across the tree of life. These models also be able to predict or test the primary mechanism for population divergence. Therefore, knowing the behavior of the models is important. This study compares the performance of three models Dirichlet process, Pitman-Yor process, and weighted-uniform(DP, PYP, and WU) that are implemented in \ecoevolity software to estimate the number of shared divergence time among 10 pairs of population in the past.Our results show that Pitman-Yor process which is the more flexible model, consistently outperforms the other two models in both simulations (with reduced data sets). The flexibility of Pitman-Yor process has some advantages, especially when it is wrong. 



    \vspace{6pt}
    \noindent\textbf{KEY WORDS:Phylogeography, divergence time, evolutionary events, Dirichlet process, Pitman-Yor process, weighted-uniform process, the behavior of models.}
    
    
\end{abstract}

\newpage

\section{Introduction}
The primary goal of biogeography is to understand how the large-scale evolutionary processes like climate change affect the diversification. Evolutionary processes have a large effect on the diversity and diversification of the species. Biogeographers are interested in knowing the biogeographic patterns among the co-distributed species. How these large-scale evolutionary processes affect the species' evolutionary history and what kind of roles these evolutionary processes play in creating the biodiversity patterns across the taxa. Climate change is one of processes that shapes the evolutionary history of the species. Climate fluctuated through the earth's history from warming to cold, glaciation to deglaciation, and arise in sea level vice verse. For some species, climate-driven mechanism is the primary mode of population divergence \citep{Oaks2019codemogpreprint}.\\ Phylogenetic models allow to capture micro and macroevolutionary processes that have generated biodiversity patterns across the tree of life \citep{Oaks2022}. Various phylogenetic models from generalized tree model to process-based models can be utilized to predict or test for the underlying mechanisms which created a diverse life on the earth. Estimating shared evolutionary events is an interest of many sub-fields of biology (biogeography etc.,). Biogeographers are interested in addressing questions like the number of shared divergence times, the timing of divergence, and whether there is a concordance between geological and biological events across the taxa. The usage of phylogenetic models in various fields of biology is wide. Therefore, knowing the behavior of models is vital for studies which depend on models to test hypotheses and obtain the results.\\
In this study, we compared the performance of 3 models (Dirichlet prior, Pitman-Yor prior and Uniform prior) 
that are implemented in \ecoevolity software which is the primary software we used to estimate the number of shared divergence time among 10 pairs of populations in the past. We are interested in how well the models have estimated the shared divergence times and how well the models have estimated which population pairs belong to which divergence time. Inferring the shared divergence time across pairs of taxa can reveal the evolutionary history of taxa. It also shows what shared mechanism is the driving force for population divergence. Temporal patterns             


We assigned prior probabilities to 3 models; how probable each model is. Dirichlet-process prior 
assigns prior to a new category with probability of \(\dfrac{1}{\concentration +1}\) and an existing category with probability of \(\dfrac{\concentration}{\concentration+1}\). The concentration parameter(\concentration) 
makes the DP flexible because we can adjust the concentration parameter to fit our prior expectation. We can put a distribution on the 
concentration parameter and integrate over uncertainty about the prior probabilities of the divergence models. Pitman-Yor process prior is 
generalization of Dirichlet process. There is a discount parameter($\discount$) added in PYP and when $\discount= 0$ PYP converges to DP. Dirichlet has an exponential tail 
and the discount parameter gives the PYP flexibility over the tail behavior. Uniform prior is every possible divergence model is equally probable. 
Then we have specified the priors in the config files for each of these 3 models that they are comparable to each other to assess the behavior of the models. 

We used these 3 config files and then added 2 more configs (independent and simultaneous configs) to simulate data sets. Independent config 
basically specifies 10 divergence times and each population diverged independently. Simultaneous config specifies that the populations 
diverged simultaneously and there is 1 shared event. And there is another config file which ignores the constant sites (characters). A total of 6 config 
files are specified to simulate the data sets. We used these 6 config files 4 times to generate scripts and then simulated 10 data sets under each of 
these 5 models with 5000,000 characters. Then we analyzed the data under 3 models and the results show that Pitman-Yor process is doing better job handling 
most difficult scenario all 10 pairs diverged independently because PYP is more flexible model. The coverage is more robust for Pitman-Yor process twice likely.
So we are interested to see whether this pattern holds with less data. We decided to do another simulation with 4 varying data sets 5,000, 10,000, 50,000, and 100,000. 
All the data sets simulated under 5 models and then analyzed these data sets under 3 models (DP, PYP, and SW). There are equal number of replicates for both simulations 
a total of 720 replicates for each simulation. We found that with varying data sets suggest the same Pitman-Yor process has 2 parameters and more flexible might 
have some advantages especially when it is wrong.

\section{Model}

Here we provide a summary of the model implemented in \ecoevolity; please see
\citet{Oaks2018ecoevolity} and \citet{Oaks2019codemog} for a full description.
Our model allows for an arbitrary number and mix of two types of temporal
comparisons:
\begin{enumerate}
    \item A population that experienced a change from effective population size
        \epopsize[\rootpopindex]
        to effective size
        \epopsize[\descendantpopindex{}]
        at time \comparisonetime in the past.
        We will refer to this as a \emph{demographic comparison},
        and refer to the population before and after the change in population
        size as ``ancestral'' and ``descendant'', respectively.
    \item A population that diverged at time \comparisonetime in the past into
        two descendant populations, each with unique effective population
        sizes.
        We will refer to this as a \emph{divergence comparison}.
\end{enumerate}
For simplicity, we will use terminology related to divergence comparisons, but
all of the theory discussed below also applies to demographic comparisons.

For each comparison, we assume we have sampled unlinked biallelic characters;
i.e., each character evolved along a gene tree that is independent of the
other characters, conditional on the population history.
We assume these characters evolved along their gene trees according to a
finite-sites continuous-time Markov chain (CTMC) model.
The equilibrium frequency (\gfreq) of the two character states can be
estimated, making the CTMC model a two-state, general, time-reversible model
\citep{Tavare1986}.
Alternatively, if the state frequencies are constrained to be equal, the CTMC
model is a two-state analog of the ``Jukes-Cantor'' model of nucleotide substitution
\citep{JC1969}.
For the divergence times to be comparable among comparisons, the relative or
absolute mutation rate (\murate) or each pair must be specified or given an
informative prior probability distribution.
\citep{Oaks2018ecoevolity,Oaks2019codemog}.

The primary goal is to infer the temporal clustering of divergences across
\ncomparisons comparisons.
At one extreme, all \ncomparisons could have diverged at the same time,
and at the other extreme, all \ncomparisons diverged independently.
This presents a model-choice problem, where the number of possible models
is the number of ways we can assign \ncomparisons comparisons to
$\nevents = 1, 2,  \ldots, \ncomparisons$ divergence times
\citep[the Bell number;][]{Bell1934}.
Below, we use \etimesets to represent the partitioning of comparisons to
divergence events, which we will also refer to as a ``divergence model,'' and
$\etimes = \etime[1], \etime[2], \ldots, \etime[\nevents]$
to represent the times of the \nevents divergence events.

We use a full-likelihood Bayesian approach to jointly infer
the divergence model (\etimesets), divergence times
(\etimes),
and comparison-specific parameters (\epopsize, \murate, and \gfreq)
\citep{Oaks2018ecoevolity,Oaks2019codemog}.
We compare three models for specifying the probability of all
possible divergence models (\etimesets):
A Dirichlet-process (DP), Pitman-Yor process (PYP), and
weighted-uniform (WU) model.
For all of these models we assume the time of each divergence event (\etime) is
distributed according to a parametric continuous probability distribution, like
a gamma distribution.

\subsection{Dirichlet-process (DP) model}

\begin{linenomath}
\citet{Oaks2018ecoevolity} treated the number of divergence events and the
assignment of comparisons to those events as random variables under a Dirichlet
process \citep{Ferguson1973, Antoniak1974}.
The concentration parameter, \concentration, controls how clustered the
Dirichlet process is, and determines the probability of all possible \etimesets
(i.e., all possible set partitions of \ncomparisons comparisons).
To get the probability of any divergence model (\etimesets), we can assign
comparisons to divergence events one at a time, in any order, following a
simple rule.
When assigning the $i^{th}$ comparison, we assign it to its own event
(i.e., a new divergence event with a unique time) with probability
\begin{equation}
    \frac{\concentration}{\concentration + i - 1},
    \label{eq:dpnewcat}
\end{equation}
or we assign it to an existing event $x$ with probability
\begin{equation}
    \frac{n_x}{\concentration + i - 1}.
    \label{eq:dpexistingcat}
\end{equation}
where $n_x$ is the number of comparisons already assigned to event $x$.
The overall probability of the divergence model is then the product of each
comparison's probability of being added to its divergence event.
\end{linenomath}

\subsection{Pitman-Yor-process (PYP) model}

\begin{linenomath}
\citet{PitmanYor1997} generalized the Dirichlet process by adding a
``discount'' parameter (\discount) that can take values from 0--1.
% The rule governing the PYP is very similar to the DP.
When assigning the $i^{th}$ comparison, we assign it to its own event
with probability
\begin{equation}
    \frac{\concentration + \nexistingcats \discount}{\concentration + i - 1},
    \label{eq:pypnewcat}
\end{equation}
where \nexistingcats is the number of events that currently exist (i.e., that have at
least one comparison assigned to it).
Alternatively, we assign it to an existing event $x$ with probability
\begin{equation}
    \frac{n_x - \discount}{\concentration + i -1}.
    \label{eq:pypexistingcat}
\end{equation}
Notice, when $\discount = 0$, the PYP is equivalent to the DP.
\end{linenomath}

\subsection{Weighted-uniform (\wunif) model}
We also implemented what we are calling a ``weighted-uniform'' (\wunif) model
that has a single ``split weight'' parameter, denoted as \splitweight, that
controls the relative probability of models with different numbers of events.
For a given model with \nevents divergence events, the relative probability
of each model with $\nevents + 1$ events is \splitweight,
and the relative probability of each model with $\nevents - 1$ events is
$\frac{1}{\splitweight}$.
More generally, the relative probability of each model with
$\nevents + n$
events is
$\splitweight{}^n$,
and the relative probability of each model with
$\nevents - n$
events is
$\frac{1}{\splitweight{}^n}$.
Models with the same number of divergence events
are always equally probable,
and
when $\splitweight = 1$, all possible divergence models (\etimesets) across all
numbers of events are equally probable.

\begin{linenomath}
To formalize this as a proper probability mass function,
the probability of any divergence model is
\begin{equation}
    p(\etimesets \given \splitweight, \ncomparisons, \nevents) = 
    \frac{
        \splitweight^{(\nevents - 1)}
    }{
        \sum\limits_{k=1}^{k=\ncomparisons} S_2(\ncomparisons, k) \splitweight^{(k-1)}
    },
    \label{eq:uniformdivmodelprob}
\end{equation}
where $S_2(\ncomparisons, k)$ is the Stirling number of the second kind which
is equal to the number of ways of assigning the \ncomparisons comparisons to
$k$ divergence events.
\end{linenomath}

\subsection{Approximating the posterior with MCMC}

We use Markov chain Monte Carlo (MCMC) algorithms to sample from the joint
posterior distribution of divergence models (\etimesets), divergence times
(\etimes), effective population sizes (\epopsize), and any mutation rate
(\murate) or substitution parameters (\gfreq) that are free to vary
\citep{Oaks2018ecoevolity,Oaks2019codemog}.
We use a suite of univariate and multivariate Metropolis-Hastings moves to
update the parameters of the model \citep{Metropolis1953,Hastings1970}.
The latter improve mixing in the face of correlations among divergence times,
population sizes, and mutation rates \citep[see][]{Oaks2018ecoevolity}.

Because \etimesets can differ in the number of divergence-time parameters, we
also need to use trans-dimensional MCMC algorithms to sample over all possible
divergence models.
Under the PYP, and the special case of the DP, the order of the comparisons
does not affect the probability of the model.
In other words, divergence models (\etimesets) that share the same integer
partition (i.e., the same number of events with the same number of comparisons
assigned to them) are equally probable.
Hence, the comparisons are exchangeable under the PYP and DP priors.
This allows us to use the Gibbs sampling algorithm (Algorithm 8) of
\citet{Neal2000} to update \etimesets during the MCMC chain.

Unlike the PYP and DP, where divergence events with the same
integer partition are equally probable, under the
\wunif prior, divergence events that share the same number of events (\nevents) are
equally probable.
This means that the comparisons are not exchangeable under the \wunif prior,
and thus Gibbs sampling will not work to sample \etimesets under the \wunif
prior.
Instead we use reversible-jump MCMC moves under the \wunif prior \citep{Green1995}.

% \subsubsection{reversible-jump MCMC}
% Layout the rjMCMC moves here \ldots


\subsection{Software implementation and project documentation}

We implemented the models outlined above in the open-source \cpp package,
\ecoevolity, which is freely available from
\url{https://github.com/phyletica/ecoevolity}, with documentation available
at
\url{http://phyletica.org/ecoevolity/}.
In the test suite of \ecoevolity, we validate model likelihood calculations and
test that the MCMC algorithms sample from the expected prior distribution when
data are ignored.
All of our analyses were performed with
Commit c1685dfa
of the \ecoevolity software package,
and all of the functionality included in this commit is part of
the release of Version \highLight{1.0.0}.
A detailed history of this project, including all of the scripts
needed to produce our results, is available at
\url{https://github.com/phyletica/ecoevolity-model-prior}
(\highLight{Cite Zenodo archive of repo here}).
% \citep{Anamza2020zenodo}.
The project repository includes detailed documentation and tutorials of our
work, which is hosted as a website at
\url{http://phyletica.org/ecoevolity-model-prior/}.

\section{Methods}

\subsection{Analyses of simulated data}

We used \simcoevolity and \ecoevolity of the \ecoevolity software
package
\citep[Commit c1685dfa][]{Oaks2018ecoevolity}
to simulate and analyze \datasets, respectively.
Each simulated \dataset comprised biallelic characters from 2 diploid
individuals (4 genomes) sampled per population from 10 pairs of populations
(i.e., 10 divergence comparisons).
We assumed the mutation rates were equal and 1 across the 10 pairs of
populations, such that time and effective population sizes are scaled by the
mutation rate.
The times of divergence events were exponentially distributed with a mean 0.05
expected substitutions per site.
The mutation-scaled effective sizes ($\epopsize\murate$) of the descendant
populations were gamma-distributed with a shape of 20 and mean of 0.001,
and the size of the ancestral population relative to the mean of its
descendants was gamma distributed with a shape of 50 and mean of 1.
These distributions were also used as priors when the simulated \datasets were
analyzed with \ecoevolity.


When analyzing each simulated \dataset with \ecoevolity,
we ran four MCMC chains for 75,000 generations with a sample taken every 50
generations.
We summarized the last 1000 samples from each chain for a total of 4000 MCMC
samples to approximate the posterior distribution for every simulated \dataset.
From the four chains of each analysis, we calculated the potential
scale reduction factor \citep[PSRF; the square root of Equation 1.1
in][]{Brooks1998} and effective sample size \citep[ESS;][]{Gong2014} for all
continuous parameters and the log likelihood using
\pycoevolity (Commit 27cb15e5).
When plotting results, we highlight any simulation replicates that have a
$\textrm{PSRF} > 1.2$.


\subsubsection{Comparing three models of shared evolutionary events}

We simulated 720 \datasets under five different models of how divergences are
clustered across 10 pairs of populations (3,600 total \datasets).
Each \dataset comprised 500,000 biallelic characters from 2 diploid individuals
per population.
The five models of divergence times were:
\begin{description}
    \item[Simultaneous] All 10 pairs of populations diverged at the same time
        (which was exponentially distributed).
    \item[Independent] All 10 pairs of populations diverged independently.
    \item[DP] Divergence times distributed according to a Dirichlet process
        where the concentration parameter is distributed as
        $\concentration \sim \dgamma{2}{5.42}$.
    \item[PYP] Divergence times distributed according to a Pitman-Yor process
        where the concentration and discount parameters are distributed as
        $\concentration \sim \dgamma{2}{3.58}$
        and
        $\discount \sim \dbeta{1}{4}$.
    \item[\wunif] Divergence times distributed according to a
        weighted-uniform distribution
        where the split-weight parameter is distributed as
        $\splitweight \sim \dgamma{0.55}{4.026}$.
\end{description}
The distributions on the concentration, discount, and split-weight parameters of
the DP, PYP, and \wunif distribution were selected such that the mean number of
divergence events is approximately 5.5
and the probability of each possible number of events
is similar among the three models.

Using \ecoevolity, we analyzed all 3,600 \datasets under the
DP, PYP, and \wunif models both using and excluding invariant characters.
This is a total of
3,600 \datasets $\times$ 3 models $\times$ 2 (with/without invariant characters) $=$ 21,600
analyses, each with four independent MCMC chains as described above.
For prior probability distributions in these analyses,
we used the same distributions described above to generate the data.


\subsubsection{Comparing DP, PYP, and \wunif across \dataset sizes}

To compare the performance of the DP, PYP, and \wunif models as a function of
\dataset size, we simulated 720
\datasets under the ``independent'' model described above, but
with 5,000, 10,000, 50,000, and 100,000 biallelic characters.
We analyzed all 2,880 \datasets under the DP, PYP, and \wunif models
both with and without invariant characters, as
described above.

\subsubsection{Quantifying the performance on simulated data}

The primary goal of methods like \ecoevolity is to infer the number of
divergence events and the assignment of the comparisons to those events
(\etimesets).
To quantify the error in estimating \etimesets from each simulated \dataset, we
used the partition distance between the true \etimesets and those sampled from
the posterior distribution of the DP, PYP, and \wunif models
\citep{Regnier1983,Gusfield2002}.
In our context, the partition distance between the true and sampled \etimesets
is the minimum number of divergence comparisons that need to be removed for the
assignment of the remaining comparisons to divergence events to match between
the two \etimesets.
% Below we will refer to this distance as \etimesets error.
To calculate this distance we used the Hungarian (or Kuhn-Munkres) algorithm
\citep{Kuhn1955,Munkres1957}
as implemented in Version 1.1.4 of the Munkres Python package
\citep{Clapper2020}.

In addition to partition distance as a metric for \etimesets error, we used
three additional statistics to quantify performance in estimating \etimesets:
$p(\hat{\etimesets} =\etimesets)$---
    the proportion of simulation replicates in which the true \etimesets had
    the maximum posterior probability,
% However, this metric can be misleading.
% For example, in our simultaneous-divergence and independent-divergence simulations,
% the true divergence model has the maximum prior probability simply because there
% is only a single model with one and 10 divergences.
% Thus, if the data provide no information, there is a 50\% chance of the true
% model having the maximum posterior probability.
$p(\etimesets \given \alldata)$---
    the posterior probability of the true divergence model,
and
$p(\etimesets \in \textrm{95\% CS})$---
    the proportion of simulation replicates for which the true \etimesets is
    included in the 95\% posterior credibility set of divergence models (i.e.,
    coverage).


\subsection{An empirical application}

To do \ldots

\section{Results}

\subsection{Analyses of simulated data}

\subsubsection{Comparing three models of shared evolutionary events}

When we compare the error in estimating the divergence model (\etimesets) and
the posterior support for the true \etimesets, we see that the WU model
underperforms relative to the DP and PYP models when applied to data generated
under the simultaneous, DP, and PYP models
(first two rows of \fig~\ref{fig:modelperformancegrid}).
The DP and PYP models show more robustness when applied to
data generated under the WU model.
As expected, we find the simulations where all 10 pairs diverged independently
to be the most challenging scenario for all three models.
The PYP model performs better than the DP and \wunif model
when analyzing these most challenging \datasets
(right-most column of \fig~\ref{fig:modelperformancegrid}).
This is true across all of the \dataset sizes we simulated
under the independent-divergences model
(\fig~\ref{fig:modelperformancebysize}).
However, the differences in performance are small and the order of the three
models mirror the small differences in prior probability they place on the
independent-divergences model.

We see similar patterns in the relative performance of the DP, PYP, and
\wunif models when only the variable characters from the simulated
\datasets are analyzed
(\figs S\ref{fig:varonlymodelperformancegrid}
and S\ref{fig:varonlymodelperformancebysize}).
However, the performance of all three models is greatly reduced when
only variable characters are used,
which is consistent with the findings of
\citet{Oaks2018ecoevolity,Oaks2018paic,Oaks2019codemog}.
We also see similar patterns when we look at the estimated
number of divergence events
(\figs S\labelcref{fig:neventsgrid,fig:varonlyneventsgrid,fig:neventsfixedcomparison,fig:varonlyneventsfixedcomparison,fig:neventsgridbysize,fig:varonlyneventsgridbysize}), however, many of the patterns are more
suitable when compared to the 

All three models performed similarly in estimating the divergence times and
effective sizes of the ancestral and descendant populations
across all of our simulations
(\figs S\labelcref{fig:divtimegrid,fig:varonlydivtimegrid,fig:divtimegridbysize,fig:varonlydivtimegridbysize,fig:ancpopsizegrid,fig:varonlyancpopsizegrid,fig:ancpopsizegridbysize,fig:varonlyancpopsizegridbysize,fig:descpopsizegrid,fig:varonlydescpopsizegrid,fig:descpopsizegridbysize,fig:varonlydescpopsizegridbysize}).
As found previously \citep{Oaks2018ecoevolity,Oaks2018paic,Oaks2019codemog}, using invariant characters results in much greater precision
in these estimates
(\figs S\labelcref{fig:divtimegrid,fig:varonlydivtimegrid,fig:divtimegridbysize,fig:varonlydivtimegridbysize,fig:ancpopsizegrid,fig:varonlyancpopsizegrid,fig:ancpopsizegridbysize,fig:varonlyancpopsizegridbysize,fig:descpopsizegrid,fig:varonlydescpopsizegrid,fig:descpopsizegridbysize,fig:varonlydescpopsizegridbysize}).

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{../images/from-project-repo/model-performance-violin-cropped.pdf}
        \captionsetup{listformat=figList}
        \caption{
        Comparing the models' ability to estimate the divergence model.
        Each column of plots compares the performance of the Dirichlet process
        (DP), Pitman-Yor process (PYP) and weighted-uniform (WU) models when
        analyzing 720 \datasets simulated under the (from left-to-right)
        simultaneous-divergence, DP, PYP, WU, and independent-divergences
        model. 
        Mean \etimesets error is the mean partition distance
        of the posterior samples from the true
        divergence model (\etimesets),
        $p(\etimesets \given \alldata)$ is the posterior probability
        of the true divergence model,
        $p(\etimesets \given \alldata)$ is the posterior probability of the
        true divergence model,
        and
        $p(\etimesets \in \textrm{95\% CS})$ is the proportion of simulation
        replicates for which the true \etimesets is included in the 95\%
        posterior credibility set of divergence models.
        The bars overlaying the violin plots show the interval between the
        2.5\% and 97.5\% percentiles, and the white dot is the median.
        We generated the plot using matplotlib Version 3.1.3
        \citep{matplotlib}.
        }
        \label{fig:modelperformancegrid}
    \end{center}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{../images/from-project-repo/nchars-model-performance-violin-cropped.pdf}
        \captionsetup{listformat=figList}
        \caption{
        Comparing the models' ability to estimate the independent-divergence
        model as the \dataset size increases.
        Each column of plots compares the performance of the Dirichlet process
        (DP), Pitman-Yor process (PYP) and weighted-uniform (WU) models when
        analyzing 720 \datasets with 5,000 to 500,000 characters simulated
        under the independent-divergences model.
        Mean \etimesets error is the mean partition distance
        of the posterior samples from the true
        divergence model (\etimesets),
        $p(\etimesets \given \alldata)$ is the posterior probability
        of the true divergence model,
        $p(\etimesets \given \alldata)$ is the posterior probability of the
        true divergence model,
        and
        $p(\etimesets \in \textrm{95\% CS})$ is the proportion of simulation
        replicates for which the true \etimesets is included in the 95\%
        posterior credibility set of divergence models.
        The bars overlaying the violin plots show the interval between the
        2.5\% and 97.5\% percentiles, and the white dot is the median.
        We generated the plot using matplotlib Version 3.1.3
        \citep{matplotlib}.
        }
        \label{fig:modelperformancebysize}
    \end{center}
\end{figure}

A description of some summary statistics that will help us to interpret the results. Coverage or credible sites is the probability
of the number of events within the credible sites. The probability of estimated number 
of events equal to the true number of events which basically tells us how often we 
are right. Median posterior probability is the true number of events given the data 
and this summary statistics tells us how much support we have for the correct answer.
Root mean square error quantifies how much error is there and comparing the true 
value to the estimate value. 
Hyper Parameter Estimation 
We are going to look how well the hyper parameters are estimated. Dirichlet
prior has as a single parameter called concentration parameter that tells how cluster 
the process is. The result of estimated concentration versus true concentration plot
shows that the true value is within 95\% credible sites. Pitman-Yor prior has two 
parameters(concentration parameter and discount parameter) the estimated value of 
concentration versus the true value indicates that the true is also within 95\%
credible sites. The Uniform prior has split weight and the result of estimated value 
versus the true value shows the true value is little less comparing to the other two 
priors but it's still within 94\% credible sites.
In this study, we are interested in divergence time and sharing divergence time and 
everything else is nuisance parameters. For both divergence time and sharing divergence time 
estimation we analyzed data with constant sites and without constant sites. First, we are going 
to look at the results of divergence time estimation with constant sites. The models which generated 
the data in rows and columns represent the models under which the data is analyzed. The true divergence 
time is on x-axis and the estimated divergence time is on y-axis. The results of true divergence 
time versus estimated divergence time show that all the three models (DP, PYP, and SW) performed
equally well with very similar coverage around 95\%. Except for independent all others have truths 
contained in within that 95\% credible interval. Independent is little lower because it's evolving 
independently and we are not modeling that way. We haven't observed any patterns that differentiate
these 3 models. Root mean square errors are very similar across all the models as well. 
With variable sites only there are more variation in estimates when throwing the invariable 
sites which contain lot of information and when we use them we have much more precision in estimates
than ignoring them. All 10 pairs diverge spontaneous recently causing some MCMC issues and there 
are very few variable sites all 10 pairs diverged recently. Basically there is discrepancy between 
gene divergence and population divergence which is the largest at the most recent divergent times.
Comparing the true number of events with estimated number of events among all the sites. The true 
divergence time ranges from 1 to 10.  1 refers they all share the divergence time and 10 means they all 
diverged independently. The true number of events is the one has the highest posterior probability.
We have 520 replicates and the grid shows how many of them are in each cell. The result shows 
that the data generated under PYP and analyzed under PYP. There are 88 data sets for which the true 
number of divergence is 5 and 76 out of those 88 got the that number correctly. 11 out of 88 
estimated 4 divergence times and 1 out of 88 estimated 3 divergence time. 
The results for two constraint models all the 3 models under which the data is analyzed show that 
half of the time there are 10 independent divergence times for the data sets that is generated under 
independent model. The models are doing very well and they got half of time the correct answer. The 
ones got wrong are not that far away from the true and they are 8 or 9 event. PYP seems like 
doing little better in terms of how often get the correct answer and also the confident in that 
correct answer. The median posterior probability for k=10 getting the correct answer
given the data is 47\% and it's little lower for the other models. The scenario of co-divergence
is an easy scenario and it has the probability of 1 for true number of event versus estimated number of 
event. When the truth is 1 the models are doing very well estimating the number of divergence time. But 
when the truth is 10 everything is diverging independently then it's more difficult scenario for 
models to handle. Therefore, there is variation in the results. 
The results of true number of events versus estimated number of events among variable sites. The
constant sites are very informative and without invariable sites, the median posterior probability
which is the correct answer is much lower. But the coverage is unaffected because the 
likelihood for the missing invariable characters is corrected in \ecoevolity. PYP is doing better when 
dealing with the most difficult scenario all the 10 pairs are diverging independently as well. Both in
terms of coverage and getting the correct answer is much higher than the other two models. 

\subsubsection{Comparing DP, PYP, and \wunif across \dataset sizes}

% #### 
% Nuisane Parameters


\subsection{Empirical application?}


\section{Discussion}


\section{Acknowledgments}

We thank \ldots
This work was supported by funding provided to JRO from the National Science
Foundation (NSF grant number DEB 1656004).
The computational work was made possible by the Auburn University (AU) Hopper
Cluster supported by the AU Office of Information Technology
and
a grant of high-performance computing resources and technical support from the
Alabama Supercomputer Authority.
This paper is contribution number \highLight{XXX} of the Auburn University
Museum of Natural History.


%TC:ignore

\bibliographystyle{evolution}
\bibliography{references}


\iflinenumbers{
\end{linenumbers}
}{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SUPPORTING INFO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}
\setcounter{section}{0}

\singlespacing

\section*{Supporting Information}
\hangindent=1cm
\noindent Title: \msTitle

\bigskip
{\noindent Authors: \msAuthor}

\newpage
\singlespacing

\input{si-body.tex}
\clearpage

\input{si-tables.tex}
\clearpage

\input{si-figures.tex}

%TC:endignore

\end{document}
